"""
âš”ï¸ PROTOCOLO NÃ‰MESIS-RETROSPECCIÃ“N: Post-Mortem EstadÃ­stico y Re-CalibraciÃ³n

QUÃ‰: Motor de autopsia tÃ©cnica y psicolÃ³gica de cada posiciÃ³n cerrada.
POR QUÃ‰: Sin retrospecciÃ³n, el bot repite errores. Compara la 'IntenciÃ³n Inicial'
     (SOPHIA) contra la 'Realidad del Mercado' para detectar sesgos, recalibrar
     confianza y penalizar genes que producen trades pobres.
PARA QUÃ‰: Cierre del bucle de aprendizaje: Error â†’ DiagnÃ³stico â†’ Ajuste â†’ Mejora.
CÃ“MO: NemesisEngine.full_autopsy() orquesta 8 analizadores especializados:
     Â§I BrierAudit â†’ Â§II TemporalForensics â†’ Â§III BiasAudit â†’ Â§IV FeedbackLoop.
CUÃNDO: Se invoca inmediatamente despuÃ©s de compute_post_mortem() en Portfolio.update_fill().
DÃ“NDE: sophia/nemesis.py
QUIÃ‰N: NemesisEngine (facade), invocado por Portfolio._sophia_post_mortem_check().
"""

import math
import os
import time
import json
from collections import deque
from dataclasses import dataclass, field
from utils.metrics_exporter import metrics
from typing import Dict, List, Optional, Any, Tuple
from datetime import datetime, timezone

from utils.logger import logger
from sophia.axioma import AxiomDiagnoser, FallaBase  # CRITERIO-AXIOMA Protocol


# ============================================================
# DATA STRUCTURES
# ============================================================

@dataclass
class NemesisReport:
    """
    ðŸ“‹ Complete autopsy result for a single closed trade.

    QUÃ‰: Reporte completo de la retrospecciÃ³n post-mortem.
    POR QUÃ‰: Centraliza los diagnÃ³sticos de TODAS las dimensiones:
         probabilÃ­stica, temporal, sesgos, eficiencia, slippage.
    PARA QUÃ‰: Trazabilidad completa + alimentaciÃ³n del feedback loop.
    """
    trade_id: str
    symbol: str
    direction: str

    # Â§I: CalibraciÃ³n ProbabilÃ­stica
    brier_score: float
    brier_bucket: str                   # "0-50%", "50-70%", "70-85%", "85-100%"
    overconfidence_active: bool         # True si penalty activo
    overconfidence_penalty_factor: float # 1.0 = sin penalizaciÃ³n
    false_positive: bool                # True si P>85% y LOSS
    false_positive_reason: str          # TAIL_EVENT / VOLATILITY_SPIKE / SIGNAL_DECAY / UNKNOWN / N/A

    # Â§II: Forense Temporal
    time_deviation_ratio: float         # actual / predicted
    time_deviation_class: str           # PRECISE / ALPHA_LEAK / VOLATILITY_STALL / PREMATURE_EXIT
    efficiency_factor: float            # PnL / duration_mins
    efficiency_class: str               # EXCELLENT / GOOD / POOR / CAPITAL_TRAPPED

    # Â§III: Sesgos Psico-Digitales
    bias_detected: str                  # NONE / PREMATURE_PROFIT / LOSS_HOLDING
    disposition_score: float            # rolling avg(loss_hold) / avg(win_hold)
    shap_accuracy: float                # feature hit rate (0-1)
    shap_mismatches: List[str]          # features that missed
    slippage_pct: float                 # |fill - trigger| / trigger Ã— 100
    slippage_alert: bool                # True si slippage > threshold

    # Â§IV: Feedback
    gene_penalty: float                 # amount deducted from fitness
    gene_flagged: bool                  # True if genotype flagged for replacement

    # CRITERIO-AXIOMA: Root Cause Diagnosis
    falla_base: str                     # CALCULO, PROFUNDIDAD, TESIS_DECAY, NO_FALLA
    residual_pct: float                 # Target vs Realized dev
    reco_accion: str                    # Accion dictada por el orÃ¡culo

    # Narrative
    manifest: str                       # Auto-critique full text
    timestamp: str = ""

    def to_dict(self) -> Dict:
        return {
            'trade_id': self.trade_id,
            'symbol': self.symbol,
            'direction': self.direction,
            'brier_score': round(self.brier_score, 4),
            'brier_bucket': self.brier_bucket,
            'overconfidence_active': self.overconfidence_active,
            'overconfidence_penalty_factor': round(self.overconfidence_penalty_factor, 3),
            'false_positive': self.false_positive,
            'false_positive_reason': self.false_positive_reason,
            'time_deviation_ratio': round(self.time_deviation_ratio, 3),
            'time_deviation_class': self.time_deviation_class,
            'efficiency_factor': round(self.efficiency_factor, 6),
            'efficiency_class': self.efficiency_class,
            'bias_detected': self.bias_detected,
            'disposition_score': round(self.disposition_score, 3),
            'shap_accuracy': round(self.shap_accuracy, 3),
            'shap_mismatches': self.shap_mismatches,
            'slippage_pct': round(self.slippage_pct, 4),
            'slippage_alert': self.slippage_alert,
            'gene_penalty': round(self.gene_penalty, 4),
            'gene_flagged': self.gene_flagged,
            'falla_base': self.falla_base,
            'residual_pct': round(self.residual_pct, 4),
            'reco_accion': self.reco_accion,
            'manifest': self.manifest,
            'timestamp': self.timestamp,
        }

    def to_log_line(self) -> str:
        bias_str = f"Sesgo: {self.bias_detected}" if self.bias_detected != "NONE" else "Sesgo: NINGUNO"
        return (
            f"[NÃ‰MESIS] Brier={self.brier_score:.3f} ({self.brier_bucket}) | "
            f"T_dev={self.time_deviation_ratio:.2f}x ({self.time_deviation_class}) | "
            f"E={self.efficiency_factor:.4f}$/min ({self.efficiency_class}) | "
            f"{bias_str} | Slip={self.slippage_pct:.3f}%"
            f"{' âš ï¸OC' if self.overconfidence_active else ''}"
            f"{' ðŸš¨FP' if self.false_positive else ''}"
            f" | AXIOM:[Falla:{self.falla_base} Dev:{self.residual_pct:.4f} ðŸ‘‰ {self.reco_accion}]"
        )


# ============================================================
# Â§I.2: OVERCONFIDENCE PENALIZER
# ============================================================

class OverconfidencePenalizer:
    """
    âš ï¸ NÃ‰MESIS Â§I.2: Adaptive Confidence Threshold Penalizer.

    QUÃ‰: Si el Brier Score promedio sube, CASTIGA la confianza del bot
         incrementando los umbrales de entrada para las prÃ³ximas 10 operaciones.
    POR QUÃ‰: Un bot con Brier > 0.20 estÃ¡ sobreestimando su capacidad predictiva.
         Necesita ser mÃ¡s conservador hasta que su calibraciÃ³n mejore.
    PARA QUÃ‰: Auto-regulaciÃ³n. El bot se "auto-frena" cuando estÃ¡ descalibrado.
    CÃ“MO: penalty_factor = 1.0 + max(0, (avg_brier - 0.15) Ã— 3.0)
         P(Win)_adjusted = P(Win) / penalty_factor
    CUÃNDO: Evaluado despuÃ©s de cada trade. Si se activa, dura 10 trades.
    """

    def __init__(self, lookback: int = 10, brier_threshold: float = 0.20):
        self.lookback = lookback
        self.brier_threshold = brier_threshold
        self.recent_briers: deque = deque(maxlen=lookback)
        self.penalty_trades_remaining = 0
        self.current_penalty_factor = 1.0

    def record_brier(self, brier: float):
        """Record a new Brier score and check if penalty should activate."""
        self.recent_briers.append(brier)

        # Decrement penalty counter
        if self.penalty_trades_remaining > 0:
            self.penalty_trades_remaining -= 1
            if self.penalty_trades_remaining == 0:
                self.current_penalty_factor = 1.0
                logger.info("âœ… [NÃ‰MESIS] PenalizaciÃ³n por exceso de confianza EXPIRADA. Umbrales restaurados.")

        # Check if we need to activate/renew penalty
        if len(self.recent_briers) >= 5:
            avg_brier = sum(self.recent_briers) / len(self.recent_briers)
            if avg_brier > self.brier_threshold:
                self.current_penalty_factor = 1.0 + max(0, (avg_brier - 0.15) * 3.0)
                self.penalty_trades_remaining = self.lookback
                logger.warning(
                    f"âš ï¸ [NÃ‰MESIS] Exceso de confianza detectado! "
                    f"Brier_avg={avg_brier:.3f}. "
                    f"Penalty factor={self.current_penalty_factor:.2f}x "
                    f"para prÃ³ximos {self.lookback} trades."
                )

    def get_penalty_factor(self) -> float:
        """Returns current penalty factor (1.0 = no penalty)."""
        return self.current_penalty_factor

    def is_active(self) -> bool:
        return self.penalty_trades_remaining > 0

    def adjust_probability(self, p_win: float) -> float:
        """Apply penalty: scale down confidence."""
        if self.current_penalty_factor <= 1.0:
            return p_win
        return max(0.01, p_win / self.current_penalty_factor)


# ============================================================
# Â§I.3: FALSE POSITIVE ANALYZER
# ============================================================

class FalsePositiveAnalyzer:
    """
    ðŸš¨ NÃ‰MESIS Â§I.3: High-Confidence Failure Diagnostics.

    QUÃ‰: Identifica si entradas con >85% de probabilidad fallaron.
    POR QUÃ‰: Un fallo cuando el bot estaba "muy seguro" es mÃ¡s grave que
         uno con 55%. Puede indicar cisnes negros o mala lectura del mercado.
    PARA QUÃ‰: Clasificar la causa raÃ­z:
         TAIL_EVENT â†’ distribuciÃ³n fat-tailed ignorada
         VOLATILITY_SPIKE â†’ GARCH vol duplicÃ³ durante el trade
         SIGNAL_DECAY â†’ trade durÃ³ >2Ã— la tesis de alfa
         UNKNOWN â†’ causas no determinables
    CÃ“MO: Al cerrar, si P_pred > 0.85 AND outcome == LOSS, analiza el SOPHIA report.
    """

    HIGH_CONFIDENCE_THRESHOLD = 0.85

    def __init__(self, fp_window: int = 20):
        self.fp_window = fp_window
        self.recent_high_conf: deque = deque(maxlen=fp_window)  # (was_loss, reason)

    def analyze(
        self,
        predicted_prob: float,
        actual_pnl: float,
        sophia_report: Dict,
        actual_duration_secs: float,
    ) -> Tuple[bool, str]:
        """
        Check if this trade is a false positive and classify the reason.

        Returns:
            (is_false_positive, reason)
        """
        is_loss = actual_pnl <= 0
        is_high_conf = predicted_prob >= self.HIGH_CONFIDENCE_THRESHOLD

        if not is_high_conf:
            return False, "N/A"

        if not is_loss:
            self.recent_high_conf.append((False, "N/A"))
            return False, "N/A"

        # High confidence + Loss = FALSE POSITIVE
        reason = self._classify_reason(sophia_report, actual_duration_secs)

        self.recent_high_conf.append((True, reason))
        logger.warning(
            f"ðŸš¨ [NÃ‰MESIS] FALSE POSITIVE: P={predicted_prob:.0%} â†’ LOSS. "
            f"RazÃ³n: {reason}"
        )

        return True, reason

    def _classify_reason(self, sophia: Dict, duration_secs: float) -> str:
        """Classify the root cause of a high-confidence failure."""
        # Check for tail event
        excess_kurt = sophia.get('excess_kurtosis', 0.0)
        if excess_kurt > 3.0:
            return "TAIL_EVENT"

        # Check for signal decay
        alpha_threshold_mins = sophia.get('alpha_decay_threshold_mins', 999)
        actual_mins = duration_secs / 60.0
        if actual_mins > 2.0 * alpha_threshold_mins and alpha_threshold_mins > 0:
            return "SIGNAL_DECAY"

        # Check GARCH volatility inconsistency (if pre-trade vol was low but
        # the trade moved violently, that's a volatility spike)
        tail_warning = sophia.get('tail_risk_warning', False)
        if tail_warning:
            return "VOLATILITY_SPIKE"

        return "UNKNOWN"

    def get_fp_rate(self) -> float:
        """Rolling false positive rate among high-confidence trades."""
        if not self.recent_high_conf:
            return 0.0
        fp_count = sum(1 for was_loss, _ in self.recent_high_conf if was_loss)
        return fp_count / len(self.recent_high_conf)

    def is_critical(self) -> bool:
        """True if FP rate exceeds 25%."""
        return self.get_fp_rate() > 0.25


# ============================================================
# Â§II.4: TIME DEVIATION ANALYZER
# ============================================================

class TimeDeviationAnalyzer:
    """
    â±ï¸ NÃ‰MESIS Â§II.4: Temporal Prediction Accuracy Auditor.

    QUÃ‰: Compara cuÃ¡nto DURÃ“ el trade vs cuÃ¡nto PREDIJO SOPHIA que durarÃ­a.
    POR QUÃ‰: Si el bot dice "10 min" y el trade dura 60 min, hay un problema:
         o el precio se estancÃ³ (volatility stall) o se filtrÃ³ el alfa (alpha leak).
    PARA QUÃ‰: Detectar ineficiencias temporales y ajustar el SurvivalEstimator.
    CÃ“MO: ratio = actual / predicted â†’ clasificar.
    """

    def __init__(self, rolling_window: int = 50):
        self.rolling_ratios: deque = deque(maxlen=rolling_window)

    def analyze(
        self,
        actual_duration_mins: float,
        predicted_duration_mins: float,
        actual_pnl: float,
    ) -> Tuple[float, str]:
        """
        Compute time deviation ratio and classify.

        Returns:
            (ratio, classification)
        """
        if predicted_duration_mins <= 0:
            predicted_duration_mins = 10.0  # Default fallback

        ratio = actual_duration_mins / predicted_duration_mins
        self.rolling_ratios.append(ratio)

        # Classify
        if 0.5 <= ratio <= 2.0:
            classification = "PRECISE"
        elif ratio > 2.0 and actual_pnl > 0:
            classification = "ALPHA_LEAK"
        elif ratio > 2.0 and actual_pnl <= 0:
            classification = "VOLATILITY_STALL"
        elif ratio < 0.5:
            classification = "PREMATURE_EXIT"
        else:
            classification = "PRECISE"

        return round(ratio, 3), classification

    def get_avg_ratio(self) -> float:
        """Rolling average time deviation ratio."""
        if not self.rolling_ratios:
            return 1.0
        return sum(self.rolling_ratios) / len(self.rolling_ratios)

    def generate_narrative(
        self,
        ratio: float,
        classification: str,
        actual_mins: float,
        predicted_mins: float,
    ) -> str:
        """Human-readable time deviation narrative."""
        narratives = {
            "PRECISE": f"DuraciÃ³n real {actual_mins:.1f}min â‰ˆ estimado {predicted_mins:.1f}min. PredicciÃ³n temporal PRECISA.",
            "ALPHA_LEAK": f"DuraciÃ³n real {actual_mins:.1f}min vs estimado {predicted_mins:.1f}min â†’ FUGA DE ALFA: ganÃ³ pero tardÃ³ {ratio:.1f}x lo esperado.",
            "VOLATILITY_STALL": f"DuraciÃ³n real {actual_mins:.1f}min vs estimado {predicted_mins:.1f}min â†’ ESTANCAMIENTO: perdiÃ³ tras esperar {ratio:.1f}x lo previsto.",
            "PREMATURE_EXIT": f"DuraciÃ³n real {actual_mins:.1f}min vs estimado {predicted_mins:.1f}min â†’ SALIDA PREMATURA: cerrÃ³ en {ratio:.1f}x del horizonte.",
        }
        return narratives.get(classification, f"Ratio temporal: {ratio:.2f}x")


# ============================================================
# Â§II.5: EFFICIENCY CALCULATOR
# ============================================================

class EfficiencyCalculator:
    """
    ðŸ“Š NÃ‰MESIS Â§II.5: Capital Efficiency Factor.

    QUÃ‰: E = PnL / Tiempo de ExposiciÃ³n ($/min).
    POR QUÃ‰: Un trade que gana $0.05 en 60 minutos es INEFICIENTE.
         Ese capital de $13 USDT estuvo "atrapado" mientras otros trades
         podÃ­an haber generado mÃ¡s retorno.
    PARA QUÃ‰: Detectar "capital traps" y mejorar la selecciÃ³n de entradas.
    CÃ“MO: E = PnL / duration_mins. E_norm = E / avg_E. Clasificar.
    """

    def __init__(self, rolling_window: int = 50):
        self.rolling_efficiencies: deque = deque(maxlen=rolling_window)

    def compute(
        self,
        actual_pnl: float,
        duration_mins: float,
    ) -> Tuple[float, float, str]:
        """
        Compute efficiency factor.

        Returns:
            (efficiency, normalized_efficiency, classification)
        """
        if duration_mins <= 0:
            duration_mins = 1.0  # Minimum 1 minute

        efficiency = actual_pnl / duration_mins
        self.rolling_efficiencies.append(efficiency)

        # Normalize against rolling average
        avg_e = self._get_avg_efficiency()
        if abs(avg_e) > 1e-8:
            e_normalized = efficiency / abs(avg_e)
        else:
            e_normalized = 1.0 if efficiency >= 0 else -1.0

        # Classify
        if e_normalized > 1.5:
            classification = "EXCELLENT"
        elif e_normalized >= 0.8:
            classification = "GOOD"
        elif actual_pnl > 0 and e_normalized < 0.3:
            classification = "CAPITAL_TRAPPED"
        else:
            classification = "POOR"

        return round(efficiency, 6), round(e_normalized, 3), classification

    def _get_avg_efficiency(self) -> float:
        if not self.rolling_efficiencies:
            return 0.0
        return sum(self.rolling_efficiencies) / len(self.rolling_efficiencies)


# ============================================================
# Â§III.6: DISPOSITION BIAS DETECTOR
# ============================================================

class DispositionBiasDetector:
    """
    ðŸ§  NÃ‰MESIS Â§III.6: Disposition Effect Auditor.

    QUÃ‰: Detecta si el bot cierra prematuramente las ganancias (miedo) o
         mantiene las pÃ©rdidas mÃ¡s allÃ¡ del tiempo proyectado (esperanza).
    POR QUÃ‰: El "sesgo de disposiciÃ³n" es el error cognitivo #1 en trading:
         vender ganadores rÃ¡pido + mantener perdedores demasiado.
         Si un bot lo hace, su cÃ³digo tiene el equivalente digital de un sesgo humano.
    PARA QUÃ‰: Diagnosticar si la lÃ³gica de SL/TP y salidas necesita ajuste.
    CÃ“MO:
         WINs: win_hold_ratio = actual_duration / time_to_tp_estimate
               Si < 0.5 â†’ PREMATURE_PROFIT_TAKING
         LOSSes: loss_hold_ratio = actual_duration / time_to_sl_estimate
               Si > 2.0 â†’ LOSS_HOLDING
         disposition_score = avg(loss_hold) / avg(win_hold)
               Si > 1.5 â†’ DISPOSITION EFFECT CONFIRMED
    """

    def __init__(self, rolling_window: int = 30):
        self.win_hold_ratios: deque = deque(maxlen=rolling_window)
        self.loss_hold_ratios: deque = deque(maxlen=rolling_window)

    def analyze(
        self,
        actual_pnl: float,
        actual_duration_mins: float,
        predicted_tp_mins: float,
        predicted_sl_mins: float,
    ) -> Tuple[str, float]:
        """
        Detect disposition bias for this trade.

        Returns:
            (bias_type, disposition_score)
        """
        is_win = actual_pnl > 0
        bias = "NONE"

        if is_win:
            if predicted_tp_mins > 0:
                ratio = actual_duration_mins / predicted_tp_mins
                self.win_hold_ratios.append(ratio)
                if ratio < 0.5:
                    bias = "PREMATURE_PROFIT"
        else:
            if predicted_sl_mins > 0:
                ratio = actual_duration_mins / predicted_sl_mins
                self.loss_hold_ratios.append(ratio)
                if ratio > 2.0:
                    bias = "LOSS_HOLDING"

        # Compute disposition score
        disposition_score = self._get_disposition_score()

        return bias, round(disposition_score, 3)

    def _get_disposition_score(self) -> float:
        """
        disposition_score = avg(loss_hold_ratios) / avg(win_hold_ratios).
        > 1.5 = confirmed disposition effect.
        """
        if not self.win_hold_ratios or not self.loss_hold_ratios:
            return 1.0  # Neutral

        avg_win = sum(self.win_hold_ratios) / len(self.win_hold_ratios)
        avg_loss = sum(self.loss_hold_ratios) / len(self.loss_hold_ratios)

        if avg_win < 0.01:
            return 1.0
        return avg_loss / avg_win

    def has_confirmed_bias(self) -> bool:
        return self._get_disposition_score() > 1.5


# ============================================================
# Â§III.7: POST-TRADE SHAP COMPARATOR
# ============================================================

class PostTradeSHAPComparator:
    """
    ðŸ“Š NÃ‰MESIS Â§III.7: Feature Attribution Accuracy Tracker.

    QUÃ‰: Compara quÃ© indicadores fueron importantes AL ENTRAR vs cuÃ¡les
         realmente movieron el precio DURANTE el trade.
    POR QUÃ‰: Si el RSI fue el factor #1 en la entrada pero el mercado respondiÃ³
         al volumen, el bot sobreestimÃ³ al RSI y subestimÃ³ al volumen.
    PARA QUÃ‰: Ajustar pesos de features en la "Trinidad Omega".
    CÃ“MO:
         1. Entry SHAP: top_features from SOPHIA (before trade)
         2. Post-trade: did the price move in the direction the feature predicted?
            - RSI oversold â†’ price went UP? â†’ HIT
            - RSI oversold â†’ price went DOWN? â†’ MISS
         3. SHAP_accuracy = hits / (hits + misses)
    """

    def __init__(self, rolling_window: int = 50):
        # Per-feature tracking: {feature_name: deque of booleans (hit=True)}
        self.feature_hits: Dict[str, deque] = {}
        self.rolling_window = rolling_window

    # Feature-to-direction mapping: how each feature predicts direction
    FEATURE_DIRECTION = {
        'RSI': 'contrarian',        # RSI oversold â†’ expect UP
        'BB Position': 'contrarian', # BB low â†’ expect UP
        'ADX': 'neutral',           # Strength, not direction
        'Volume Ratio': 'confirming', # High vol confirms signal direction
        'MTF Confluence': 'confirming',
        'MACD Histogram': 'momentum', # MACD+ â†’ UP
        'Trend Alignment': 'confirming',
        'ATR %': 'neutral',
    }

    def analyze(
        self,
        top_features: List[Dict],
        actual_pnl: float,
        direction: str,
    ) -> Tuple[float, List[str]]:
        """
        Compare pre-trade feature attributions against actual outcome.

        Returns:
            (shap_accuracy, list_of_mismatched_features)
        """
        if not top_features:
            return 1.0, []

        hits = 0
        misses = 0
        mismatches = []
        trade_succeeded = actual_pnl > 0

        for feat in top_features:
            name = feat.get('feature', '')
            contribution = feat.get('contribution', 0.0)

            # A feature "hit" if:
            # - Its contribution was positive AND the trade won, OR
            # - Its contribution was negative AND the trade lost
            # (i.e., the feature correctly predicted the outcome)
            feature_predicted_success = contribution > 0
            is_hit = feature_predicted_success == trade_succeeded

            if is_hit:
                hits += 1
            else:
                misses += 1
                mismatches.append(name)

            # Track per-feature accuracy
            if name not in self.feature_hits:
                self.feature_hits[name] = deque(maxlen=self.rolling_window)
            self.feature_hits[name].append(is_hit)

        total = hits + misses
        accuracy = hits / total if total > 0 else 1.0

        return round(accuracy, 3), mismatches

    def get_feature_accuracy(self, feature_name: str) -> float:
        """Rolling accuracy for a specific feature."""
        hits = self.feature_hits.get(feature_name, deque())
        if not hits:
            return 1.0
        return sum(1 for h in hits if h) / len(hits)

    def get_underperforming_features(self, threshold: float = 0.40) -> List[str]:
        """Features with accuracy below threshold â†’ candidate for weight reduction."""
        weak = []
        for name, hits in self.feature_hits.items():
            if len(hits) >= 10:  # Need enough data
                acc = sum(1 for h in hits if h) / len(hits)
                if acc < threshold:
                    weak.append(name)
        return weak


# ============================================================
# Â§III.8: SLIPPAGE FORENSICS
# ============================================================

class SlippageForensics:
    """
    ðŸ“‰ NÃ‰MESIS Â§III.8: Trigger vs Fill Price Forensics.

    QUÃ‰: Cuantifica la diferencia entre el precio al generar la seÃ±al
         y el precio real de ejecuciÃ³n.
    POR QUÃ‰: En scalping con $13 USDT, un slippage de 0.05% = $0.0065 que
         se come directamente el PnL. Con trades que buscan 0.5-1.5% de TP,
         un slippage de 0.1% es CATASTRÃ“FICO (comerÃ­a 10-20% del profit).
    PARA QUÃ‰: Si el slippage es recurrente, recalibrar el motor de ejecuciÃ³n.
    CÃ“MO: slippage_pct = |fill_price - trigger_price| / trigger_price Ã— 100
    """

    def __init__(self, rolling_window: int = 100, alert_threshold_pct: float = 0.05):
        self.rolling_slippages: deque = deque(maxlen=rolling_window)
        self.alert_threshold = alert_threshold_pct

    def compute(
        self,
        trigger_price: float,
        fill_price: float,
    ) -> Tuple[float, bool]:
        """
        Compute slippage percentage and check alert threshold.

        Returns:
            (slippage_pct, is_alert)
        """
        if trigger_price <= 0:
            return 0.0, False

        slippage = abs(fill_price - trigger_price) / trigger_price * 100.0
        self.rolling_slippages.append(slippage)

        is_alert = self.get_avg_slippage() > self.alert_threshold

        return round(slippage, 4), is_alert

    def get_avg_slippage(self) -> float:
        if not self.rolling_slippages:
            return 0.0
        return sum(self.rolling_slippages) / len(self.rolling_slippages)

    def get_p95_slippage(self) -> float:
        if len(self.rolling_slippages) < 5:
            return 0.0
        sorted_s = sorted(self.rolling_slippages)
        idx = int(len(sorted_s) * 0.95)
        return sorted_s[min(idx, len(sorted_s) - 1)]

    def get_max_slippage(self) -> float:
        if not self.rolling_slippages:
            return 0.0
        return max(self.rolling_slippages)


# ============================================================
# Â§IV.9: GENE PENALIZER
# ============================================================

class GenePenalizer:
    """
    ðŸ§¬ NÃ‰MESIS Â§IV.9: Genetic Algorithm Fitness Penalty.

    QUÃ‰: Reduce el fitness_score del Genotype que produjo un trade con Brier pobre.
    POR QUÃ‰: Los genes que repetidamente hacen predicciones incorrectas deben ser
         marcados como "recesivos" para evitar que se repliquen en la flota.
    PARA QUÃ‰: PresiÃ³n evolutiva hacia genes mejor calibrados.
    CÃ“MO: brier_penalty = brier_score Ã— 0.5. Si 3+ consecutivas pobres â†’ flag replacement.
    """

    POOR_BRIER_THRESHOLD = 0.30

    def __init__(self):
        self.consecutive_poor: Dict[str, int] = {}  # genotype_id â†’ count

    def evaluate(
        self,
        brier_score: float,
        axioma: AxiomDiagnoser, # CRITERIO-AXIOMA integration
        genotype_id: str = "default",
    ) -> Tuple[float, bool]:
        """
        Compute gene penalty and check for replacement flag.
        Returns: (penalty_amount, should_flag_for_replacement)
        """
        # CRITERIO-AXIOMA: Safe-Mode on Math Calculation Errors
        if axioma.tipo_falla == FallaBase.CALCULO:
            logger.error(f"â˜ ï¸ [NÃ‰MESIS] Error de CÃ¡lculo detectado (Slippage/PrecisiÃ³n). Posible Safe-Mode trigger.")
            # We don't penalize the genotype for engine bugs, but we alert loudly.
            return 0.0, False
            
        # CRITERIO-AXIOMA: Severe penalty on Thesis Decay
        if axioma.tipo_falla == FallaBase.TESIS_DECAY:
            self.consecutive_poor[genotype_id] = self.consecutive_poor.get(genotype_id, 0) + 1
            # Double the Brier penalty because the model fundamentally failed the macro regime
            penalty = brier_score * 1.0 
            should_flag = self.consecutive_poor[genotype_id] >= 2 # Stricter: 2 strikes out
            
            if should_flag:
                logger.warning(
                    f"ðŸ§¬ [NÃ‰MESIS] Genotype '{genotype_id}' flagged for REPLACEMENT: "
                    f"Failures on TESIS_DECAY."
                )
            return round(penalty, 4), should_flag
            
        # CRITERIO-AXIOMA: Premium on NO_FALLA
        if axioma.tipo_falla == FallaBase.NO_FALLA:
            # Reward context: we return a negative penalty (bonus)
            self.consecutive_poor[genotype_id] = 0
            return -0.5, False # -0.5 is a fitness bonus

        # Standard Brier Evaluation
        if brier_score <= self.POOR_BRIER_THRESHOLD:
            # Good trade â€” reset consecutive counter
            self.consecutive_poor[genotype_id] = 0
            return 0.0, False

        # Poor trade
        penalty = brier_score * 0.5
        self.consecutive_poor[genotype_id] = self.consecutive_poor.get(genotype_id, 0) + 1

        should_flag = self.consecutive_poor[genotype_id] >= 3

        if should_flag:
            logger.warning(
                f"ðŸ§¬ [NÃ‰MESIS] Genotype '{genotype_id}' flagged for REPLACEMENT: "
                f"{self.consecutive_poor[genotype_id]} consecutive poor trades."
            )

        return round(penalty, 4), should_flag


# ============================================================
# Â§IV.10: MANIFEST WRITER
# ============================================================

class ManifestWriter:
    """
    ðŸ“ NÃ‰MESIS Â§IV.10: Auto-Critique Narrative Generator.

    QUÃ‰: Genera una conclusiÃ³n en lenguaje humano de lo que fallÃ³ (o acertÃ³).
    POR QUÃ‰: "PensÃ© que ganarÃ­a por X, pero perdÃ­ por Y. Error de calibraciÃ³n
         detectado en el mÃ³dulo de Volatilidad. Ajustando umbrales."
    PARA QUÃ‰: Trazabilidad humana + debugging + lecciones automÃ¡ticas.
    CÃ“MO: Template engine con datos del NemesisReport.
    """

    LOG_DIR = os.path.join("sophia", "nemesis_logs")

    @staticmethod
    def generate_manifest(
        trade_id: str,
        symbol: str,
        direction: str,
        predicted_prob: float,
        actual_pnl: float,
        brier_score: float,
        time_deviation_class: str,
        efficiency_class: str,
        bias_detected: str,
        false_positive_reason: str,
        shap_mismatches: List[str],
        overconfidence_active: bool,
        penalty_factor: float,
        axioma: AxiomDiagnoser,
        gene_penalty: float,
    ) -> str:
        """Generate the full auto-critique manifest."""
        outcome = "ganÃ©" if actual_pnl > 0 else "perdÃ­"
        outcome_emoji = "âœ…" if actual_pnl > 0 else "âŒ"

        # Build reason chain
        reasons = []

        if false_positive_reason == "TAIL_EVENT":
            reasons.append("evento de cola gruesa (cisne negro)")
        elif false_positive_reason == "VOLATILITY_SPIKE":
            reasons.append("spike de volatilidad no anticipado")
        elif false_positive_reason == "SIGNAL_DECAY":
            reasons.append("la seÃ±al expirÃ³ antes de alcanzar el objetivo")

        if time_deviation_class == "ALPHA_LEAK":
            reasons.append("fuga de alfa â€” el movimiento fue mÃ¡s lento que lo predicho")
        elif time_deviation_class == "VOLATILITY_STALL":
            reasons.append("estancamiento por baja volatilidad")
        elif time_deviation_class == "PREMATURE_EXIT":
            reasons.append("salida prematura â€” el precio no tuvo tiempo de moverse")

        if bias_detected == "PREMATURE_PROFIT":
            reasons.append("sesgo de disposiciÃ³n: cerrÃ© ganancias prematuramente")
        elif bias_detected == "LOSS_HOLDING":
            reasons.append("sesgo de disposiciÃ³n: mantuve pÃ©rdidas por esperanza")

        if efficiency_class == "CAPITAL_TRAPPED":
            reasons.append("capital atrapado â€” baja eficiencia temporal")

        if shap_mismatches:
            mm = ", ".join(shap_mismatches[:3])
            reasons.append(f"features que fallaron: {mm}")

        reason_str = "; ".join(reasons) if reasons else "ejecuciÃ³n limpia"

        # Build adjustments
        adjustments = []
        if overconfidence_active:
            pct = (penalty_factor - 1.0) * 100
            adjustments.append(f"Umbrales de entrada +{pct:.0f}% por penalizaciÃ³n de confianza")
        if shap_mismatches:
            adjustments.append(f"Reducir peso de {', '.join(shap_mismatches[:2])} en prÃ³ximas seÃ±ales")
        if bias_detected != "NONE":
            adjustments.append("Revisar lÃ³gica de SL/TP para corregir sesgo de disposiciÃ³n")
            
        # CRITERIO-AXIOMA Additions
        if axioma.tipo_falla != FallaBase.NO_FALLA:
            adjustments.append(f"OrÃ¡culo Axioma: {axioma.razon} ({axioma.accion_recomendada})")
        if gene_penalty > 0:
            adjustments.append(f"Restados {gene_penalty:.2f} pts al Genoma")
        elif gene_penalty < 0:
            adjustments.append(f"Sumados {-gene_penalty:.2f} pts al Genoma (Premio Axioma)")

        adjust_str = ". ".join(adjustments) if adjustments else "Sin ajustes necesarios"

        expectation = "ganarÃ­a" if actual_pnl > 0 else "perderÃ­a"

        manifest = (
            f"{outcome_emoji} PensÃ© que {expectation} con {predicted_prob:.0%} de probabilidad "
            f"en {symbol} {direction}, y {outcome} (PnL=${actual_pnl:+.4f}). "
            f"Brier={brier_score:.4f}. "
            f"DiagnÃ³stico: {reason_str}. "
            f"Ajuste: {adjust_str}."
        )

        return manifest

    @staticmethod
    def persist_to_disk(trade_id: str, nemesis_report: Dict):
        """Save manifest as JSON to sophia/nemesis_logs/."""
        try:
            os.makedirs(ManifestWriter.LOG_DIR, exist_ok=True)
            filepath = os.path.join(
                ManifestWriter.LOG_DIR,
                f"nemesis_{trade_id[:12]}_{datetime.now(timezone.utc).strftime('%Y%m%d_%H%M%S')}.json"
            )
            import json
            with open(filepath, 'w', encoding='utf-8') as f:
                json.dump(nemesis_report, f, indent=2, ensure_ascii=False, default=str)
        except Exception as e:
            logger.error(f"[NÃ‰MESIS] Failed to persist manifest: {e}")


# ============================================================
# Â§I.1: BRIER BUCKET ANALYZER
# ============================================================

class BrierBucketAnalyzer:
    """
    ðŸ“Š NÃ‰MESIS Â§I.1: Enhanced Brier Score by Probability Bucket.

    QUÃ‰: Segmenta el Brier Score por rango de probabilidad predicha.
    POR QUÃ‰: Un Brier promedio de 0.15 puede esconder que el bot es EXCELENTE
         en trades de 50-70% pero PÃ‰SIMO en trades de 85-100%. El anÃ¡lisis
         por bucket revela dÃ³nde estÃ¡ descalibrado.
    PARA QUÃ‰: Saber en quÃ© rango de confianza confiar.
    """

    BUCKETS = {
        "0-50%": (0.0, 0.50),
        "50-70%": (0.50, 0.70),
        "70-85%": (0.70, 0.85),
        "85-100%": (0.85, 1.01),
    }

    def __init__(self):
        self.bucket_data: Dict[str, List[float]] = {b: [] for b in self.BUCKETS}

    def record(self, predicted_prob: float, brier_score: float):
        """Record a Brier score to the appropriate bucket."""
        for bucket_name, (lo, hi) in self.BUCKETS.items():
            if lo <= predicted_prob < hi:
                self.bucket_data[bucket_name].append(brier_score)
                return

    def get_bucket(self, predicted_prob: float) -> str:
        """Get which bucket a probability falls into."""
        for bucket_name, (lo, hi) in self.BUCKETS.items():
            if lo <= predicted_prob < hi:
                return bucket_name
        return "85-100%"

    def get_bucket_analysis(self) -> Dict[str, Dict]:
        """Returns per-bucket Brier mean and count."""
        analysis = {}
        for bucket_name, scores in self.bucket_data.items():
            if scores:
                analysis[bucket_name] = {
                    'mean_brier': round(sum(scores) / len(scores), 4),
                    'count': len(scores),
                    'worst': round(max(scores), 4),
                }
            else:
                analysis[bucket_name] = {
                    'mean_brier': 0.0,
                    'count': 0,
                    'worst': 0.0,
                }
        return analysis


# ============================================================
# FACADE: NEMESIS ENGINE
# ============================================================

class NemesisEngine:
    """
    âš”ï¸ NÃ‰MESIS-RETROSPECCIÃ“N: Full Autopsy Facade.

    QUÃ‰: Punto de entrada Ãºnico para ejecutar todos los diagnÃ³sticos post-mortem.
    POR QUÃ‰: Portfolio solo llama `nemesis.full_autopsy(...)` y recibe un
         NemesisReport completo con diagnÃ³stico, narrativa y acciones correctivas.
    PARA QUÃ‰: Cierre del bucle de aprendizaje: Error â†’ DiagnÃ³stico â†’ Ajuste â†’ Mejora.
    CÃ“MO: Orquesta: BrierBucket â†’ OverconfidencePenalizer â†’ FalsePositiveAnalyzer â†’
         TimeDeviationAnalyzer â†’ EfficiencyCalculator â†’ DispositionBiasDetector â†’
         PostTradeSHAPComparator â†’ SlippageForensics â†’ GenePenalizer â†’ ManifestWriter.
    CUÃNDO: DespuÃ©s de cada trade cerrado, invocado por Portfolio.
    DÃ“NDE: sophia/nemesis.py â†’ NemesisEngine
    QUIÃ‰N: Portfolio._sophia_post_mortem_check()
    """

    def __init__(self):
        # Â§I: CalibraciÃ³n
        self.brier_buckets = BrierBucketAnalyzer()
        self.overconfidence = OverconfidencePenalizer(lookback=10, brier_threshold=0.20)
        self.false_positives = FalsePositiveAnalyzer(fp_window=20)

        # Â§II: Temporal
        self.time_deviation = TimeDeviationAnalyzer(rolling_window=50)
        self.efficiency = EfficiencyCalculator(rolling_window=50)

        # Â§III: Sesgos
        self.disposition = DispositionBiasDetector(rolling_window=30)
        self.shap_comparator = PostTradeSHAPComparator(rolling_window=50)
        self.slippage = SlippageForensics(rolling_window=100, alert_threshold_pct=0.05)

        # Â§IV: Feedback
        self.gene_penalizer = GenePenalizer()

        logger.info("âš”ï¸ [NÃ‰MESIS] RetrospecciÃ³n engine initialized")

    def full_autopsy(
        self,
        trade_id: str,
        symbol: str,
        direction: str,
        predicted_prob: float,
        predicted_exit_mins: float,
        predicted_tp_mins: float,
        predicted_sl_mins: float,
        actual_pnl: float,
        actual_duration_mins: float,
        brier_score: float,
        sophia_report: Dict,
        top_features: List[Dict],
        trigger_price: float = 0.0,
        fill_price: float = 0.0,
        genotype_id: str = "default",
        persist_manifest: bool = True,
    ) -> NemesisReport:
        """
        Execute complete post-mortem autopsy.

        QUÃ‰: Ejecuta TODOS los diagnÃ³sticos Â§I-Â§IV en secuencia.
        POR QUÃ‰: Un solo mÃ©todo para obtener el diagnÃ³stico completo.
        PARA QUÃ‰: Portfolio lo invoca con una sola llamada.

        Returns:
            NemesisReport with all fields populated.
        """
        ts = datetime.now(timezone.utc).isoformat()
        start_time = time.perf_counter()

        # â”€â”€ Â§I.1: Brier Bucket â”€â”€
        brier_bucket = self.brier_buckets.get_bucket(predicted_prob)
        self.brier_buckets.record(predicted_prob, brier_score)

        # â”€â”€ Â§I.2: Overconfidence â”€â”€
        self.overconfidence.record_brier(brier_score)
        oc_active = self.overconfidence.is_active()
        oc_factor = self.overconfidence.get_penalty_factor()

        # â”€â”€ Â§I.3: False Positive â”€â”€
        is_fp, fp_reason = self.false_positives.analyze(
            predicted_prob, actual_pnl, sophia_report, actual_duration_mins * 60
        )

        # â”€â”€ Â§II.4: Time Deviation â”€â”€
        time_ratio, time_class = self.time_deviation.analyze(
            actual_duration_mins, predicted_exit_mins, actual_pnl
        )

        # â”€â”€ Â§II.5: Efficiency â”€â”€
        eff, eff_norm, eff_class = self.efficiency.compute(
            actual_pnl, actual_duration_mins
        )

        # â”€â”€ Â§III.6: Disposition Bias â”€â”€
        bias, disp_score = self.disposition.analyze(
            actual_pnl, actual_duration_mins, predicted_tp_mins, predicted_sl_mins
        )

        # â”€â”€ Â§III.7: Post-Trade SHAP â”€â”€
        shap_acc, shap_misses = self.shap_comparator.analyze(
            top_features, actual_pnl, direction
        )

        # â”€â”€ Â§III.8: Slippage â”€â”€
        slip_pct, slip_alert = self.slippage.compute(trigger_price, fill_price)

        # â”€â”€ Criterio-Axioma: Root Cause Diagnosis â”€â”€
        axioma = AxiomDiagnoser.diagnose(
            pnl=actual_pnl,
            direction=direction,
            trigger_price=trigger_price,
            fill_price=fill_price,
            sophia_report=sophia_report or {},
            duration_mins=actual_duration_mins
        )

        # â”€â”€ Â§IV.9: Gene Penalty â”€â”€
        gene_pen, gene_flag = self.gene_penalizer.evaluate(brier_score, axioma, genotype_id)

        # â”€â”€ Â§IV.10: Manifest â”€â”€
        manifest = ManifestWriter.generate_manifest(
            trade_id=trade_id,
            symbol=symbol,
            direction=direction,
            predicted_prob=predicted_prob,
            actual_pnl=actual_pnl,
            brier_score=brier_score,
            time_deviation_class=time_class,
            efficiency_class=eff_class,
            bias_detected=bias,
            false_positive_reason=fp_reason,
            shap_mismatches=shap_misses,
            overconfidence_active=oc_active,
            penalty_factor=oc_factor,
            axioma=axioma,
            gene_penalty=gene_pen
        )

        # Build report
        report = NemesisReport(
            trade_id=trade_id,
            symbol=symbol,
            direction=direction,
            brier_score=brier_score,
            brier_bucket=brier_bucket,
            overconfidence_active=oc_active,
            overconfidence_penalty_factor=oc_factor,
            false_positive=is_fp,
            false_positive_reason=fp_reason,
            time_deviation_ratio=time_ratio,
            time_deviation_class=time_class,
            efficiency_factor=eff,
            efficiency_class=eff_class,
            bias_detected=bias,
            disposition_score=disp_score,
            shap_accuracy=shap_acc,
            shap_mismatches=shap_misses,
            slippage_pct=slip_pct,
            slippage_alert=slip_alert,
            gene_penalty=gene_pen,
            gene_flagged=gene_flag,
            falla_base=axioma.tipo_falla.value,
            residual_pct=axioma.residual_pct,
            reco_accion=axioma.accion_recomendada,
            manifest=manifest,
            timestamp=ts,
        )

        # Log
        logger.info(f"   âš”ï¸ {report.to_log_line()}")
        logger.info(f"   ðŸ“ {manifest}")

        # â”€â”€ SOPHIA-VIEW: Emit Prometheus Metrics & Loki JSON Log â”€â”€
        try:
            latency_ms = (time.perf_counter() - start_time) * 1000.0
            metrics.record_nemesis_autopsy(
                symbol=symbol,
                actual_pnl=actual_pnl,
                brier_score=brier_score,
                brier_bucket=brier_bucket,
                predicted_mins=predicted_exit_mins,
                actual_mins=actual_duration_mins,
                efficiency=eff,
                shap_accuracy=shap_acc,
                mismatches=shap_misses,
                overconfidence_active=oc_active,
                penalty_factor=oc_factor,
                gene_flagged=gene_flag,
                genotype_id=genotype_id,
                latency_ms=latency_ms
            )
            
            loki_payload = {
                "type": "nemesis_event",
                "trade_id": trade_id,
                "symbol": symbol,
                "direction": direction,
                "predicted_mins": round(predicted_exit_mins, 2),
                "actual_mins": round(actual_duration_mins, 2),
                "brier_score": round(brier_score, 4),
                "latency_ms": round(latency_ms, 2),
                "axioma_falla": axioma.tipo_falla.value,
                "axioma_residual": round(axioma.residual_pct, 4)
            }
            logger.info(json.dumps(loki_payload))
        except Exception as e:
            logger.debug(f"[SOPHIA-VIEW] Metrics emission skipped: {e}")

        # Persist to disk
        if persist_manifest:
            ManifestWriter.persist_to_disk(trade_id, report.to_dict())

        return report

    def get_calibration_health(self) -> Dict:
        """Returns comprehensive calibration health summary."""
        return {
            'brier_buckets': self.brier_buckets.get_bucket_analysis(),
            'overconfidence': {
                'active': self.overconfidence.is_active(),
                'penalty_factor': self.overconfidence.get_penalty_factor(),
                'remaining_trades': self.overconfidence.penalty_trades_remaining,
            },
            'false_positive_rate': round(self.false_positives.get_fp_rate(), 3),
            'fp_critical': self.false_positives.is_critical(),
            'avg_time_deviation': round(self.time_deviation.get_avg_ratio(), 3),
            'disposition_bias': self.disposition.has_confirmed_bias(),
            'weak_features': self.shap_comparator.get_underperforming_features(),
            'avg_slippage_pct': round(self.slippage.get_avg_slippage(), 4),
            'p95_slippage_pct': round(self.slippage.get_p95_slippage(), 4),
        }
